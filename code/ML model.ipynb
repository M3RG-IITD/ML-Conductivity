{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aef82767",
   "metadata": {},
   "source": [
    "## M3RG LAB IIT Delhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66efb4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import random\n",
    "import time\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6731ac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('ML_Data5.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4aacd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,2:]\n",
    "Y=df.iloc[:,1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d85ff164",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y= np.log(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76de43d",
   "metadata": {},
   "source": [
    "## Error Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92f5216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "def get_score(base='Training', actual=0,predicted=0):\n",
    "    r2 = r2_score(actual,predicted)\n",
    "    mae = mean_absolute_error(actual,predicted)\n",
    "    mse = mean_squared_error(actual,predicted)\n",
    "    rmse = (mean_squared_error(actual,predicted))**(1.2)\n",
    "    #print(f'{base} has R^2={r2.round(3)}, mse={mse.round(3)} and mae={mae.round(3)}')\n",
    "    return print(f'{base} has R^2={r2.round(5)}, mse={mse.round(5)}, mae={mae.round(5)} and rmse={rmse.round(5)} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f84d138",
   "metadata": {},
   "source": [
    "## Random Forest with out CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d15ece5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has R^2=0.96995, mse=0.06876, mae=0.20869 and rmse=0.04025 \n",
      "Test has R^2=0.93071, mse=0.24469, mae=0.42555 and rmse=0.18465 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=33)\n",
    "scaler= StandardScaler().fit(X_train)\n",
    "x_train= scaler.transform(X_train)\n",
    "x_test= scaler.transform(X_test)\n",
    "Rfreg=RandomForestRegressor(n_estimators=13,random_state=30)#13,30\n",
    "model=Rfreg.fit(x_train,y_train.values.ravel())\n",
    "get_score('Training',actual=y_train,predicted=model.predict(x_train))\n",
    "get_score('Test',actual=y_test,predicted=model.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804c6def",
   "metadata": {},
   "source": [
    "### RF_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb457902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fa7ed1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator: 10\n",
      "random_state: 23\n",
      "Best_score 0.8585176962640514\n",
      "Test R2: 0.9695488332044742\n",
      "Validation R2: 0.8585176962640514\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train= shuffle(X, Y, random_state=32)\n",
    "reg_xgb=RandomForestRegressor()\n",
    "hyperparameter_grid = {\n",
    "'n_estimators': [10],\n",
    "'random_state': [23]\n",
    "}\n",
    "clf = GridSearchCV(reg_xgb, hyperparameter_grid, cv=5, verbose=0,return_train_score=True,scoring='r2') \n",
    "best_model = clf.fit(X_train, Y_train.values.ravel())\n",
    "print(\"estimator:\", best_model.best_estimator_.get_params()['n_estimators'])\n",
    "print(\"random_state:\", best_model.best_estimator_.get_params()['random_state'])\n",
    "print(\"Best_score\", best_model.best_score_)\n",
    "print(\"Test R2:\",best_model.cv_results_['mean_train_score'][np.argmin(best_model.cv_results_['rank_test_score'])])\n",
    "print(\"Validation R2:\", best_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86cc7d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator: 10\n",
      "random_state: 23\n",
      "Best_score 0.3846556712203498\n",
      "Test MSE: 0.07832160643810397\n",
      "Validation MSE: 0.3846556712203498\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train= shuffle(X, Y, random_state=32)\n",
    "reg_xgb=RandomForestRegressor()\n",
    "hyperparameter_grid = {\n",
    "'n_estimators': [10],\n",
    "'random_state': [23]\n",
    "}\n",
    "clf = GridSearchCV(reg_xgb, hyperparameter_grid, cv=5, verbose=0,return_train_score=True,scoring='neg_mean_squared_error') \n",
    "best_model = clf.fit(X_train, Y_train.values.ravel())\n",
    "print(\"estimator:\", best_model.best_estimator_.get_params()['n_estimators'])\n",
    "print(\"random_state:\", best_model.best_estimator_.get_params()['random_state'])\n",
    "print(\"Best_score\", -best_model.best_score_)\n",
    "print(\"Test MSE:\",-best_model.cv_results_['mean_train_score'][np.argmin(best_model.cv_results_['rank_test_score'])])\n",
    "print(\"Validation MSE:\", -best_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e8ebb4",
   "metadata": {},
   "source": [
    "## Xg Boost with out CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5051ab38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has R^2=0.9512, mse=0.11165, mae=0.24827 and rmse=0.07201 \n",
      "Test has R^2=0.86206, mse=0.48716, mae=0.47661 and rmse=0.4219 \n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=33)\n",
    "scaler= StandardScaler().fit(X_train)\n",
    "x_train= scaler.transform(X_train)\n",
    "x_test= scaler.transform(X_test)\n",
    "xgbr=XGBRegressor(verbosity=0,n_estimators=28, max_depth=5, random_state=33 , gamma = 0.5)\n",
    "model=xgbr.fit(x_train,y_train)\n",
    "get_score('Training',actual=y_train,predicted=model.predict(x_train))\n",
    "#get_score('validation',actual=y_val,predicted=model.predict(x_val))\n",
    "get_score('Test',actual=y_test,predicted=model.predict(x_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6cf5f3",
   "metadata": {},
   "source": [
    "### XG_Boost_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d14778df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca1e4dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 29\n",
      "max_depth: 4\n",
      "random_state: 20\n",
      "gamma: 0.4\n",
      "Best_score 0.8355561575460062\n",
      "Test R2: 0.9584262761815869\n",
      "Validation R2: 0.8355561575460062\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train= shuffle(X, Y, random_state=32)\n",
    "reg_xgb=XGBRegressor()\n",
    "hyperparameter_grid = {\n",
    "'n_estimators': [i for i in range(25,30)],\n",
    "'max_depth': [4,5],\n",
    "'random_state': [i for i in range(20,35)],\n",
    "'gamma':[0.4,0.5]\n",
    "}\n",
    "clf = GridSearchCV(reg_xgb, hyperparameter_grid, cv=5, verbose=0,return_train_score=True,scoring='r2') \n",
    "best_model = clf.fit(X_train, Y_train.values.ravel())\n",
    "print(\"n_estimators:\", best_model.best_estimator_.get_params()['n_estimators'])\n",
    "print(\"max_depth:\", best_model.best_estimator_.get_params()['max_depth'])\n",
    "print(\"random_state:\", best_model.best_estimator_.get_params()['random_state'])\n",
    "print(\"gamma:\", best_model.best_estimator_.get_params()['gamma'])\n",
    "print(\"Best_score\", best_model.best_score_)\n",
    "print(\"Test R2:\",best_model.cv_results_['mean_train_score'][np.argmin(best_model.cv_results_['rank_test_score'])])\n",
    "print(\"Validation R2:\", best_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99585d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator: 29\n",
      "random_state: 4\n",
      "random_state: 20\n",
      "random_state: 0.4\n",
      "Best_score 0.4214111885671947\n",
      "Test MSE: 0.10639275022674152\n",
      "Validation MSE: 0.4214111885671947\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train= shuffle(X, Y, random_state=32)\n",
    "reg_xgb=XGBRegressor()\n",
    "hyperparameter_grid = {\n",
    "'n_estimators': [29],\n",
    "'max_depth': [4],\n",
    "'random_state': [20],\n",
    "'gamma':[0.4]\n",
    "}\n",
    "clf = GridSearchCV(reg_xgb, hyperparameter_grid, cv=5, verbose=0,return_train_score=True,scoring='neg_mean_squared_error') \n",
    "best_model = clf.fit(X_train, Y_train.values.ravel())\n",
    "print(\"estimator:\", best_model.best_estimator_.get_params()['n_estimators'])\n",
    "print(\"random_state:\", best_model.best_estimator_.get_params()['max_depth'])\n",
    "print(\"random_state:\", best_model.best_estimator_.get_params()['random_state'])\n",
    "print(\"random_state:\", best_model.best_estimator_.get_params()['gamma'])\n",
    "print(\"Best_score\", -best_model.best_score_)\n",
    "print(\"Test MSE:\",-best_model.cv_results_['mean_train_score'][np.argmin(best_model.cv_results_['rank_test_score'])])\n",
    "print(\"Validation MSE:\", -best_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159d8b7e",
   "metadata": {},
   "source": [
    "## Elastic Net with out CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7773e028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has R^2=0.85904, mse=0.38723, mae=0.47346 and rmse=0.32031 \n",
      "Test has R^2=0.81207, mse=0.32754, mae=0.55303 and rmse=0.26201 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "model= ElasticNet(alpha=0.4)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=40)\n",
    "x_train= X_train\n",
    "x_test= X_test\n",
    "model.fit(x_train,y_train)\n",
    "get_score('Training',actual=y_train,predicted=model.predict(x_train))\n",
    "get_score('Test',actual=y_test,predicted=model.predict(x_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc183b7",
   "metadata": {},
   "source": [
    "### Elastic NET_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b8223fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.21000000000000002\n",
      "Best_score 0.8018892129466193\n",
      "Test R2: 0.8739018472544091\n",
      "Validation R2: 0.8018892129466193\n",
      "Test R2: 0.8739018472544091\n",
      "Validation R2: 0.8018892129466193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/indrajeetmandal/opt/anaconda3/envs/indr/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.761e-02, tolerance: 5.346e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/indrajeetmandal/opt/anaconda3/envs/indr/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.307e-02, tolerance: 6.093e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/indrajeetmandal/opt/anaconda3/envs/indr/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.471e-02, tolerance: 5.604e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/indrajeetmandal/opt/anaconda3/envs/indr/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.444e-02, tolerance: 5.608e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/indrajeetmandal/opt/anaconda3/envs/indr/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.313e-02, tolerance: 5.010e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train= shuffle(X, Y, random_state=32)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "reg_xgb=ElasticNet()\n",
    "hyperparameter_grid = {\n",
    "'alpha': [i for i in np.arange(0.01,1,0.1)],\n",
    "'l1_ratio':[0.5],\n",
    "'max_iter':[1000]\n",
    "    \n",
    "}\n",
    "clf = GridSearchCV(reg_xgb, hyperparameter_grid, cv=5, verbose=0,return_train_score=True,scoring='r2') \n",
    "best_model = clf.fit(X_train, Y_train.values.ravel())\n",
    "print(\"alpha:\", best_model.best_estimator_.get_params()['alpha'])\n",
    "print(\"Best_score\", best_model.best_score_)\n",
    "print(\"Test R2:\",best_model.cv_results_['mean_train_score'][np.argmin(best_model.cv_results_['rank_test_score'])])\n",
    "print(\"Validation R2:\", best_model.best_score_)\n",
    "print(\"Test R2:\",best_model.cv_results_['mean_train_score'][np.argmin(best_model.cv_results_['rank_test_score'])])\n",
    "print(\"Validation R2:\", best_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "faf284a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.6100000000000001\n",
      "Best_score -0.465102167749228\n",
      "Test R2: -0.3358671350575122\n",
      "Validation MSE: 0.465102167749228\n",
      "Test MSE: 0.3358671350575122\n",
      "Validation MSE: 0.465102167749228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/indrajeetmandal/opt/anaconda3/envs/indr/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.761e-02, tolerance: 5.346e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/indrajeetmandal/opt/anaconda3/envs/indr/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.307e-02, tolerance: 6.093e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/indrajeetmandal/opt/anaconda3/envs/indr/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.471e-02, tolerance: 5.604e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/indrajeetmandal/opt/anaconda3/envs/indr/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.444e-02, tolerance: 5.608e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/indrajeetmandal/opt/anaconda3/envs/indr/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.313e-02, tolerance: 5.010e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train= shuffle(X, Y, random_state=32)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "reg_xgb=ElasticNet()\n",
    "hyperparameter_grid = {\n",
    "'alpha': [i for i in np.arange(0.01,1,0.1)],\n",
    "'l1_ratio':[0.5],\n",
    "'max_iter':[1000]\n",
    "    \n",
    "}\n",
    "clf = GridSearchCV(reg_xgb, hyperparameter_grid, cv=5, verbose=0,return_train_score=True,scoring='neg_mean_squared_error') \n",
    "best_model = clf.fit(X_train, Y_train.values.ravel())\n",
    "print(\"alpha:\", best_model.best_estimator_.get_params()['alpha'])\n",
    "print(\"Best_score\", best_model.best_score_)\n",
    "print(\"Test R2:\",best_model.cv_results_['mean_train_score'][np.argmin(best_model.cv_results_['rank_test_score'])])\n",
    "print(\"Validation MSE:\", -best_model.best_score_)\n",
    "print(\"Test MSE:\",-best_model.cv_results_['mean_train_score'][np.argmin(best_model.cv_results_['rank_test_score'])])\n",
    "print(\"Validation MSE:\", -best_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d50982",
   "metadata": {},
   "source": [
    "## LASSO REGRESSION WITH OUT CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf83c7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has R^2=0.86076, mse=0.34866, mae=0.48898 and rmse=0.28241 \n",
      "Test has R^2=0.8543, mse=0.40694, mae=0.50778 and rmse=0.33996 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=60)\n",
    "x_train= X_train\n",
    "x_test= X_test\n",
    "model = Lasso(alpha=0.2)\n",
    "model.fit(x_train,y_train)\n",
    "get_score('Training',actual=y_train,predicted=model.predict(x_train))\n",
    "get_score('Test',actual=y_test,predicted=model.predict(x_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6898098b",
   "metadata": {},
   "source": [
    "## lasso_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "286728c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.11\n",
      "Best_score 0.8018778071510632\n",
      "Test R2: 0.8738138733217445\n",
      "Validation R2: 0.8018778071510632\n",
      "Test R2: 0.8738138733217445\n",
      "Validation R2: 0.8018778071510632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/indrajeetmandal/opt/anaconda3/envs/indr/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.325e-02, tolerance: 5.346e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train= shuffle(X, Y, random_state=32)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "reg_xgb=Lasso()\n",
    "hyperparameter_grid = {\n",
    "'alpha': [i for i in np.arange(0.01,1,0.1)]\n",
    "    \n",
    "}\n",
    "clf = GridSearchCV(reg_xgb, hyperparameter_grid, cv=5, verbose=0,return_train_score=True,scoring='r2') \n",
    "best_model = clf.fit(X_train, Y_train.values.ravel())\n",
    "print(\"alpha:\", best_model.best_estimator_.get_params()['alpha'])\n",
    "print(\"Best_score\", best_model.best_score_)\n",
    "print(\"Test R2:\",best_model.cv_results_['mean_train_score'][np.argmin(best_model.cv_results_['rank_test_score'])])\n",
    "print(\"Validation R2:\", best_model.best_score_)\n",
    "print(\"Test R2:\",best_model.cv_results_['mean_train_score'][np.argmin(best_model.cv_results_['rank_test_score'])])\n",
    "print(\"Validation R2:\", best_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c81e824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.31000000000000005\n",
      "Best_score -0.46549114811217895\n",
      "Test R2: -0.3358936809158267\n",
      "Validation MSE: 0.46549114811217895\n",
      "Test MSE: 0.3358936809158267\n",
      "Validation MSE: 0.46549114811217895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/indrajeetmandal/opt/anaconda3/envs/indr/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.325e-02, tolerance: 5.346e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train= shuffle(X, Y, random_state=32)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "reg_xgb=Lasso()\n",
    "hyperparameter_grid = {\n",
    "'alpha': [i for i in np.arange(0.01,1,0.1)]\n",
    "    \n",
    "}\n",
    "clf = GridSearchCV(reg_xgb, hyperparameter_grid, cv=5, verbose=0,return_train_score=True,scoring='neg_mean_squared_error') \n",
    "best_model = clf.fit(X_train, Y_train.values.ravel())\n",
    "print(\"alpha:\", best_model.best_estimator_.get_params()['alpha'])\n",
    "print(\"Best_score\", best_model.best_score_)\n",
    "print(\"Test R2:\",best_model.cv_results_['mean_train_score'][np.argmin(best_model.cv_results_['rank_test_score'])])\n",
    "print(\"Validation MSE:\", -best_model.best_score_)\n",
    "print(\"Test MSE:\",-best_model.cv_results_['mean_train_score'][np.argmin(best_model.cv_results_['rank_test_score'])])\n",
    "print(\"Validation MSE:\", -best_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea5b96c",
   "metadata": {},
   "source": [
    "## LINEAR REGRESSION with out CV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af806812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has R^2=0.86084, mse=0.38229, mae=0.47941 and rmse=0.31541 \n",
      "Test has R^2=0.85001, mse=0.26141, mae=0.48432 and rmse=0.19989 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=40)\n",
    "scaler= StandardScaler().fit(X_train)\n",
    "x_train= scaler.transform(X_train)\n",
    "x_test= scaler.transform(X_test)\n",
    "model= LinearRegression()\n",
    "model.fit(x_train,y_train)\n",
    "get_score('Training',actual=y_train,predicted=model.predict(x_train))\n",
    "get_score('Test',actual=y_test,predicted=model.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9aa9f2",
   "metadata": {},
   "source": [
    "## Linear_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "16a7a3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_jobs: 10\n",
      "Best_score 0.7884777165160228\n",
      "Test R2: 0.8746581717243689\n",
      "Validation R2: 0.7884777165160228\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train= shuffle(X, Y, random_state=32)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg_xgb=LinearRegression()\n",
    "hyperparameter_grid = {\n",
    "'n_jobs':[10]\n",
    "    \n",
    "}\n",
    "clf = GridSearchCV(reg_xgb, hyperparameter_grid, cv=5, verbose=0,return_train_score=True,scoring='r2') \n",
    "best_model = clf.fit(X_train, Y_train.values.ravel())\n",
    "print(\"n_jobs:\", best_model.best_estimator_.get_params()['n_jobs'])\n",
    "print(\"Best_score\", best_model.best_score_)\n",
    "print(\"Test R2:\",best_model.cv_results_['mean_train_score'][np.argmin(best_model.cv_results_['rank_test_score'])])\n",
    "print(\"Validation R2:\", best_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "894c5fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_jobs: 10\n",
      "Best_score 0.5112271474048514\n",
      "Test MSE: 0.31987130101153294\n",
      "Validation MSE: 0.5112271474048514\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train= shuffle(X, Y, random_state=32)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg_xgb=LinearRegression()\n",
    "hyperparameter_grid = {\n",
    "'n_jobs':[10]\n",
    "    \n",
    "}\n",
    "clf = GridSearchCV(reg_xgb, hyperparameter_grid, cv=5, verbose=0,return_train_score=True,scoring='neg_mean_squared_error') \n",
    "best_model = clf.fit(X_train, Y_train.values.ravel())\n",
    "print(\"n_jobs:\", best_model.best_estimator_.get_params()['n_jobs'])\n",
    "print(\"Best_score\", -best_model.best_score_)\n",
    "print(\"Test MSE:\",-best_model.cv_results_['mean_train_score'][np.argmin(best_model.cv_results_['rank_test_score'])])\n",
    "print(\"Validation MSE:\", -best_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff3f9a5",
   "metadata": {},
   "source": [
    "## SVM ANALYSIS with out CV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e7d3ee7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has R^2=0.88118, mse=0.29753, mae=0.42489 and rmse=0.23347 \n",
      "Test has R^2=0.8739, mse=0.35219, mae=0.4576 and rmse=0.28585 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=60)\n",
    "model=SVR(kernel='rbf')\n",
    "model.fit(x_train,y_train.values.ravel())\n",
    "get_score('Training',actual=y_train,predicted=model.predict(x_train))\n",
    "get_score('Test',actual=y_test,predicted=model.predict(x_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c4b17cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel: rbf\n",
      "Best_score 0.8242137710664397\n",
      "Test R2: 0.885322952709178\n",
      "Validation R2: 0.8242137710664397\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train= shuffle(X, Y, random_state=32)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "kernel='rbf'\n",
    "reg_xgb=SVR()\n",
    "hyperparameter_grid = {\n",
    "'kernel':[kernel]\n",
    "    \n",
    "}\n",
    "clf = GridSearchCV(reg_xgb, hyperparameter_grid, cv=5, verbose=0,return_train_score=True,scoring='r2') \n",
    "best_model = clf.fit(X_train, Y_train.values.ravel())\n",
    "print(\"kernel:\", best_model.best_estimator_.get_params()['kernel'])\n",
    "print(\"Best_score\", best_model.best_score_)\n",
    "print(\"Test R2:\",best_model.cv_results_['mean_train_score'][np.argmin(best_model.cv_results_['rank_test_score'])])\n",
    "print(\"Validation R2:\", best_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dac625bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel: rbf\n",
      "Best_score 0.4173546461150626\n",
      "Test MSE: 0.2931423972274\n",
      "Validation MSE: 0.4173546461150626\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train= shuffle(X, Y, random_state=32)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "kernel='rbf'\n",
    "reg_xgb=SVR()\n",
    "hyperparameter_grid = {\n",
    "'kernel':[kernel]\n",
    "    \n",
    "}\n",
    "clf = GridSearchCV(reg_xgb, hyperparameter_grid, cv=5, verbose=0,return_train_score=True,scoring='neg_mean_squared_error') \n",
    "best_model = clf.fit(X_train, Y_train.values.ravel())\n",
    "print(\"kernel:\", best_model.best_estimator_.get_params()['kernel'])\n",
    "print(\"Best_score\", -best_model.best_score_)\n",
    "print(\"Test MSE:\",-best_model.cv_results_['mean_train_score'][np.argmin(best_model.cv_results_['rank_test_score'])])\n",
    "print(\"Validation MSE:\", -best_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec064b8d",
   "metadata": {},
   "source": [
    "## ANN REGRESSION with out CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aaa4f884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b94e3560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has R^2=0.92251, mse=0.21289, mae=0.35797 and rmse=0.15623 \n",
      "Test has R^2=0.91669, mse=0.14519, mae=0.31159 and rmse=0.09871 \n"
     ]
    }
   ],
   "source": [
    "for i in range(76): \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=40)\n",
    "    x_train= X_train\n",
    "    x_test= X_test\n",
    "    model= MLPRegressor(hidden_layer_sizes=7, max_iter=10000, alpha = 0.2, random_state=i)\n",
    "    model.fit(x_train,y_train.values.ravel())\n",
    "get_score('Training',actual=y_train.values.ravel(),predicted=model.predict(x_train))\n",
    "get_score('Test',actual=y_test,predicted=model.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c41a2e9",
   "metadata": {},
   "source": [
    "## ANN_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab3a772f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/indrajeetmandal/opt/anaconda3/envs/indr/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/indrajeetmandal/opt/anaconda3/envs/indr/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/indrajeetmandal/opt/anaconda3/envs/indr/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/indrajeetmandal/opt/anaconda3/envs/indr/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/indrajeetmandal/opt/anaconda3/envs/indr/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_layer_sizes 7\n",
      "max_iter 1000\n",
      "alpha 0.2\n",
      "Best_score -17.934953015831436\n",
      "Test R2: -17.515189420075224\n",
      "Validation R2: -17.934953015831436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/indrajeetmandal/opt/anaconda3/envs/indr/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train= shuffle(X, Y, random_state=32)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "reg_xgb=MLPRegressor()\n",
    "hyperparameter_grid = {\n",
    "'hidden_layer_sizes':[7], \n",
    "'max_iter':[1000], \n",
    "'alpha':[0.2]    \n",
    "}\n",
    "clf = GridSearchCV(reg_xgb, hyperparameter_grid, cv=5, verbose=0,return_train_score=True,scoring='r2') \n",
    "best_model = clf.fit(X_train, Y_train.values.ravel())\n",
    "print(\"hidden_layer_sizes\", best_model.best_estimator_.get_params()['hidden_layer_sizes'])\n",
    "print(\"max_iter\", best_model.best_estimator_.get_params()['max_iter'])\n",
    "print(\"alpha\", best_model.best_estimator_.get_params()['alpha'])\n",
    "print(\"Best_score\", best_model.best_score_)\n",
    "print(\"Test R2:\",best_model.cv_results_['mean_train_score'][np.argmin(best_model.cv_results_['rank_test_score'])])\n",
    "print(\"Validation R2:\", best_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9b430636",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/indrajeetmandal/opt/anaconda3/envs/indr/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/indrajeetmandal/opt/anaconda3/envs/indr/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/indrajeetmandal/opt/anaconda3/envs/indr/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_layer_sizes 7\n",
      "max_iter 1000\n",
      "alpha 0.8\n",
      "Best_score 0.9600377390246481\n",
      "Test MSE: 0.5219166985398909\n",
      "Validation MSE: 0.9600377390246481\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train= shuffle(X, Y, random_state=32)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "reg_xgb=MLPRegressor()\n",
    "hyperparameter_grid = {\n",
    "'hidden_layer_sizes':[7], \n",
    "'max_iter':[1000], \n",
    "'alpha':[0.8]    \n",
    "}\n",
    "clf = GridSearchCV(reg_xgb, hyperparameter_grid, cv=5, verbose=0,return_train_score=True,scoring='neg_mean_squared_error') \n",
    "best_model = clf.fit(X_train, Y_train.values.ravel())\n",
    "print(\"hidden_layer_sizes\", best_model.best_estimator_.get_params()['hidden_layer_sizes'])\n",
    "print(\"max_iter\", best_model.best_estimator_.get_params()['max_iter'])\n",
    "print(\"alpha\", best_model.best_estimator_.get_params()['alpha'])\n",
    "print(\"Best_score\", -best_model.best_score_)\n",
    "print(\"Test MSE:\",-best_model.cv_results_['mean_train_score'][np.argmin(best_model.cv_results_['rank_test_score'])])\n",
    "print(\"Validation MSE:\", -best_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af8c489",
   "metadata": {},
   "source": [
    "## GPR with out CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a4dfaa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.gaussian_process as gp\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=475)\n",
    "scaler= StandardScaler().fit(X_train)\n",
    "x_train= X_train\n",
    "x_test= X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "45c65009",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel =  gp.kernels.ConstantKernel(1.0,(1e-2,1e3))*gp.kernels.RBF(10.0, (1e-3, 1e3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "338ed1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gp.GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, alpha=0.02, normalize_y=True)\n",
    "model.fit(x_train,y_train)\n",
    "params = model.kernel_.get_params()\n",
    "y_pred, std = model.predict(x_test, return_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ab3eed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has R^2=0.9906, mse=0.02317, mae=0.09163 and rmse=0.01091 \n",
      "Test has R^2=0.9707, mse=0.0539, mae=0.19697 and rmse=0.03006 \n"
     ]
    }
   ],
   "source": [
    "get_score('Training',actual=y_train,predicted=model.predict(x_train))\n",
    "get_score('Test',actual=y_test,predicted=model.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2335e129",
   "metadata": {},
   "source": [
    "## GPR_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "06a3fa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "import sklearn.gaussian_process as gp\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0a0516d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_restarts_optimizer: 10\n",
      "kernel: 1**2 * RBF(length_scale=1)\n",
      "alpha: 0.076\n",
      "random_state: 22 \n",
      "\n",
      "Test R2: 0.9505191655933991\n",
      "Validation R2: 0.8964253931465832\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train,Y_train= shuffle(X, Y, random_state=433)#433,2508,2892,3533,954,1332,1601,1839,2512,5582,#11239,79,749,1475,433\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=1659)#550,1659\n",
    "kernel =  gp.kernels.ConstantKernel(1,(1e-2,1e3))*gp.kernels.RBF(1, (1e-3, 1e3))\n",
    "reg_xgb=gp.GaussianProcessRegressor()\n",
    "hyperparameter_grid = {\n",
    "'kernel':[kernel], \n",
    "'n_restarts_optimizer':[10], \n",
    "'alpha':[0.076], \n",
    "'normalize_y':[True],\n",
    "'random_state':[22]\n",
    "}\n",
    "clf = GridSearchCV(reg_xgb, hyperparameter_grid, cv=5, verbose=0,return_train_score=True,scoring='r2')\n",
    "best_model = clf.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "print(\"n_restarts_optimizer:\", best_model.best_estimator_.get_params()['n_restarts_optimizer'])\n",
    "print(\"kernel:\", best_model.best_estimator_.get_params()['kernel'])\n",
    "print(\"alpha:\", best_model.best_estimator_.get_params()['alpha'])\n",
    "print(\"random_state:\", best_model.best_estimator_.get_params()['random_state'],\"\\n\")\n",
    "print(\"Test R2:\",best_model.cv_results_['mean_train_score'][np.argmin(best_model.cv_results_['rank_test_score'])])\n",
    "print(\"Validation R2:\", best_model.best_score_)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8385cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7eb1d920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_restarts_optimizer: 10\n",
      "kernel: 1**2 * RBF(length_scale=1)\n",
      "alpha: 0.076\n",
      "random_state: 22 \n",
      "\n",
      "Test MSE: 0.9661552558463062\n",
      "Validation MSE: 0.8953844939318041\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=433)#550,1659\n",
    "kernel =  gp.kernels.ConstantKernel(1.0,(1e-2,1e3))*gp.kernels.RBF(1.0, (1e-3, 1e3))\n",
    "reg_xgb=gp.GaussianProcessRegressor()\n",
    "hyperparameter_grid = {\n",
    "'kernel':[kernel], \n",
    "'n_restarts_optimizer':[10], \n",
    "'alpha':[0.076], \n",
    "'normalize_y':[True],\n",
    "'random_state':[22]\n",
    "}\n",
    "clf = GridSearchCV(reg_xgb, hyperparameter_grid, cv=5, verbose=0,return_train_score=True,scoring='r2') \n",
    "best_model = clf.fit(X_train, Y_train.values.ravel())\n",
    "print(\"n_restarts_optimizer:\", best_model.best_estimator_.get_params()['n_restarts_optimizer'])\n",
    "print(\"kernel:\", best_model.best_estimator_.get_params()['kernel'])\n",
    "print(\"alpha:\", best_model.best_estimator_.get_params()['alpha'])\n",
    "print(\"random_state:\", best_model.best_estimator_.get_params()['random_state'],\"\\n\")\n",
    "print(\"Test MSE:\",best_model.cv_results_['mean_train_score'][np.argmin(best_model.cv_results_['rank_test_score'])])\n",
    "print(\"Validation MSE:\", best_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d40a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901329de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ae97c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8abc567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24efa335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebcb235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
